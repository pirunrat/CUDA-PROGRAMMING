{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae574c96",
   "metadata": {},
   "source": [
    "# KERNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef152dbb",
   "metadata": {},
   "source": [
    "A kernel is a function executed on the GPU in a CUDA program. It's initialized from the host (also known as CPU) and executed in pararellel by many threads on the device (also known as GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f2849",
   "metadata": {},
   "source": [
    "![Basic Kernel](pictures/basic_kernal.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab8b305",
   "metadata": {},
   "source": [
    "As shown in the picture, the kernel is defined just like a C++ function where `__global__` indicates that the function runs on the GPU and is called from the CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0ae74",
   "metadata": {},
   "source": [
    "**`idx`** is the global thread index used to uniquely identify each thread across the entire grid.  \n",
    "`blockIdx.x` indicates the index of the current block within the grid.  \n",
    "`blockDim.x` specifies the number of threads per block.  \n",
    "`threadIdx.x` is the threadâ€™s index within its block."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
